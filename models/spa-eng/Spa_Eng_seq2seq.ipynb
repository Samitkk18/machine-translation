{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spa-Eng-seq2seq.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdundVLN9uuC",
        "outputId": "7d82e5f0-f63f-4530-b9a2-897c99b2ca70"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeaRh5cM-gx_",
        "outputId": "fe31a001-75cc-400b-eca1-9fcc02187e0b"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import time\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import random\n",
        "\n",
        "import nltk                         # import NLTK to handle simple NL tasks like tokenization.\n",
        "nltk.download(\"punkt\")\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter     # import the Counter module.\n",
        "#!pip3 install 'sacrebleu'           # install the sacrebleu package.\n",
        "import sacrebleu                    # import sacrebleu in order compute the BLEU score.\n",
        "\n",
        "import statistics"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjXcgTN5-y9G"
      },
      "source": [
        "# Global parameters\n",
        "#root folder\n",
        "root_folder='/content/drive/MyDrive/machine-translation/'\n",
        "#data_folder='.'\n",
        "data_folder_name='corpus/spa-eng'\n",
        "train_filename='spa.txt'\n",
        "\n",
        "# Variable for data directory\n",
        "DATA_PATH = os.path.abspath(os.path.join(root_folder, data_folder_name))\n",
        "train_filenamepath = os.path.abspath(os.path.join(DATA_PATH, train_filename))\n",
        "\n",
        "# Both train and test set are in the root data directory\n",
        "train_path = DATA_PATH\n",
        "test_path = DATA_PATH"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9s6USIkr-1IH",
        "outputId": "571068c7-cc16-4495-9538-95f22193d2b0"
      },
      "source": [
        "train_filenamepath"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/machine-translation/corpus/spa-eng/spa.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCUFwsvK-2fV"
      },
      "source": [
        "# Parameters for our model\n",
        "INPUT_COLUMN = 'input'\n",
        "TARGET_COLUMN = 'target'\n",
        "TARGET_FOR_INPUT = 'target_for_input'\n",
        "NUM_SAMPLES = 120000 #40000\n",
        "MAX_VOCAB_SIZE = 20000\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 1024 #512\n",
        "\n",
        "BATCH_SIZE = 128  # Batch size for training.\n",
        "EPOCHS = 10  # Number of epochs to train for.\n",
        "\n",
        "ATTENTION_FUNC='general'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEXwZbzO_EQ_"
      },
      "source": [
        "#Preprocessing the data\n",
        "# Some function to preprocess the text data, taken from the Neural machine translation with attention tutorial in Tensorflow\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    ''' Preprocess the input text w applying lowercase, removing accents, \n",
        "    creating a space between a word and the punctuation following it and \n",
        "    replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    Input:\n",
        "        - w: a string, input text\n",
        "    Output:\n",
        "        - a string, the cleaned text\n",
        "    '''\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.strip()\n",
        "\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    #w = '<start> ' + w + ' <end>'\n",
        "    \n",
        "    return w"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEVxX1XF_KVX"
      },
      "source": [
        "# Load the dataset: sentence in english, sentence in spanish \n",
        "df=pd.read_csv(train_filenamepath, sep=\"\\t\", header=None, names=[TARGET_COLUMN,INPUT_COLUMN], usecols=[0,1], \n",
        "               nrows=NUM_SAMPLES)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "zc7WSyWC_Oaf",
        "outputId": "810521a4-dba2-4b15-d9ae-de5573cbd0b6"
      },
      "source": [
        "df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>input</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Ve.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vete.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vaya.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Váyase.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Hola.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119995</th>\n",
              "      <td>What happened to the book I put here yesterday?</td>\n",
              "      <td>¿Qué le pasó al libro que dejé aquí ayer?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119996</th>\n",
              "      <td>What on earth do you want to talk to Tom about?</td>\n",
              "      <td>¿De qué diablos quieres hablar con Tom?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119997</th>\n",
              "      <td>What time was it when you entered the building?</td>\n",
              "      <td>¿Qué hora era cuando entraste en el edificio?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119998</th>\n",
              "      <td>What we want to do next is check the oil level.</td>\n",
              "      <td>Lo que queremos hacer es medir el nivel de ace...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119999</th>\n",
              "      <td>What were you and Tom talking about last night?</td>\n",
              "      <td>¿De qué hablabais Tom y tú ayer por la noche?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 target                                              input\n",
              "0                                                   Go.                                                Ve.\n",
              "1                                                   Go.                                              Vete.\n",
              "2                                                   Go.                                              Vaya.\n",
              "3                                                   Go.                                            Váyase.\n",
              "4                                                   Hi.                                              Hola.\n",
              "...                                                 ...                                                ...\n",
              "119995  What happened to the book I put here yesterday?          ¿Qué le pasó al libro que dejé aquí ayer?\n",
              "119996  What on earth do you want to talk to Tom about?            ¿De qué diablos quieres hablar con Tom?\n",
              "119997  What time was it when you entered the building?      ¿Qué hora era cuando entraste en el edificio?\n",
              "119998  What we want to do next is check the oil level.  Lo que queremos hacer es medir el nivel de ace...\n",
              "119999  What were you and Tom talking about last night?      ¿De qué hablabais Tom y tú ayer por la noche?\n",
              "\n",
              "[120000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_HFfLzwzAHy"
      },
      "source": [
        "train, test = train_test_split(df, test_size=0.2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Ru9A2bnpzJ1U",
        "outputId": "0d494b7e-d822-4de6-aac0-aacb00e1fb87"
      },
      "source": [
        "train"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>input</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>114938</th>\n",
              "      <td>Tom and Mary finally decided to get married.</td>\n",
              "      <td>Tom y Mary finalmente decidieron casarse.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90791</th>\n",
              "      <td>I realized that that box was empty.</td>\n",
              "      <td>Me di cuenta de que esa caja estaba vacía.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41806</th>\n",
              "      <td>I haven't forgotten her.</td>\n",
              "      <td>No la he olvidado.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36909</th>\n",
              "      <td>I know what I'm saying.</td>\n",
              "      <td>Yo sé lo que estoy diciendo.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48529</th>\n",
              "      <td>This article is for sale.</td>\n",
              "      <td>Este artículo está a la venta.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100610</th>\n",
              "      <td>I've been waiting for her for an hour.</td>\n",
              "      <td>La estoy esperando hace una hora.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97108</th>\n",
              "      <td>I don't want to go to lunch with Tom.</td>\n",
              "      <td>No quiero ir a almorzar con Tom.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98645</th>\n",
              "      <td>Tom can't find what he's looking for.</td>\n",
              "      <td>Tom no puede encontrar lo que está buscando.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34874</th>\n",
              "      <td>We left him some cake.</td>\n",
              "      <td>Le dejamos un poco de tarta.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24107</th>\n",
              "      <td>I'm going to Boston.</td>\n",
              "      <td>Voy a ir a Boston.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              target                                         input\n",
              "114938  Tom and Mary finally decided to get married.     Tom y Mary finalmente decidieron casarse.\n",
              "90791            I realized that that box was empty.    Me di cuenta de que esa caja estaba vacía.\n",
              "41806                       I haven't forgotten her.                            No la he olvidado.\n",
              "36909                        I know what I'm saying.                  Yo sé lo que estoy diciendo.\n",
              "48529                      This article is for sale.                Este artículo está a la venta.\n",
              "...                                              ...                                           ...\n",
              "100610        I've been waiting for her for an hour.             La estoy esperando hace una hora.\n",
              "97108          I don't want to go to lunch with Tom.              No quiero ir a almorzar con Tom.\n",
              "98645          Tom can't find what he's looking for.  Tom no puede encontrar lo que está buscando.\n",
              "34874                         We left him some cake.                  Le dejamos un poco de tarta.\n",
              "24107                           I'm going to Boston.                            Voy a ir a Boston.\n",
              "\n",
              "[96000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "jkh712IPzKW6",
        "outputId": "02980b20-f7d5-4492-850f-65ca94503e42"
      },
      "source": [
        "test"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>input</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>59403</th>\n",
              "      <td>Can't you make up your mind?</td>\n",
              "      <td>¿No puedes decidirte?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85135</th>\n",
              "      <td>Tom offered Mary a glass of wine.</td>\n",
              "      <td>Tomás le ofreció una copa de vino a María.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64613</th>\n",
              "      <td>He can speak Russian as well.</td>\n",
              "      <td>Él también puede hablar ruso.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103334</th>\n",
              "      <td>I've been trying to get your attention.</td>\n",
              "      <td>He estado tratando de captar tu atención.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31337</th>\n",
              "      <td>Do you like that song?</td>\n",
              "      <td>¿Te gusta esta canción?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66963</th>\n",
              "      <td>That's almost the same thing.</td>\n",
              "      <td>Es casi la misma cosa.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116823</th>\n",
              "      <td>Tom was quite good-looking when he was young.</td>\n",
              "      <td>Tom era bastante lindo cuando era joven.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65633</th>\n",
              "      <td>I once knew someone like you.</td>\n",
              "      <td>Una vez conocí a alguien como tú.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9692</th>\n",
              "      <td>I'll let Tom go.</td>\n",
              "      <td>Dejaré ir a Tom.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97002</th>\n",
              "      <td>I clicked the first link on the page.</td>\n",
              "      <td>Hice click al primer enlace en la página.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               target                                       input\n",
              "59403                    Can't you make up your mind?                       ¿No puedes decidirte?\n",
              "85135               Tom offered Mary a glass of wine.  Tomás le ofreció una copa de vino a María.\n",
              "64613                   He can speak Russian as well.               Él también puede hablar ruso.\n",
              "103334        I've been trying to get your attention.   He estado tratando de captar tu atención.\n",
              "31337                          Do you like that song?                     ¿Te gusta esta canción?\n",
              "...                                               ...                                         ...\n",
              "66963                   That's almost the same thing.                      Es casi la misma cosa.\n",
              "116823  Tom was quite good-looking when he was young.    Tom era bastante lindo cuando era joven.\n",
              "65633                   I once knew someone like you.           Una vez conocí a alguien como tú.\n",
              "9692                                 I'll let Tom go.                            Dejaré ir a Tom.\n",
              "97002           I clicked the first link on the page.   Hice click al primer enlace en la página.\n",
              "\n",
              "[24000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvakLoF1y4wg",
        "outputId": "1abc43ee-3ff1-4862-db1c-a441a6fd28da"
      },
      "source": [
        "# Preprocess the input data\n",
        "input_data=train[INPUT_COLUMN].apply(lambda x : preprocess_sentence(x)).tolist()\n",
        "# Preprocess and include the end of sentence token to the target text\n",
        "target_data=train[TARGET_COLUMN].apply(lambda x : preprocess_sentence(x)+ ' <eos>').tolist()\n",
        "# Preprocess and include a start of setence token to the input text to the decoder, it is right shifted\n",
        "target_input_data=train[TARGET_COLUMN].apply(lambda x : '<sos> '+ preprocess_sentence(x)).tolist()\n",
        "\n",
        "print(input_data[:3])\n",
        "print(target_data[:3])\n",
        "print(target_input_data[:3])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tom y mary finalmente decidieron casarse .', 'me di cuenta de que esa caja estaba vacia .', 'no la he olvidado .']\n",
            "['tom and mary finally decided to get married . <eos>', 'i realized that that box was empty . <eos>', 'i haven t forgotten her . <eos>']\n",
            "['<sos> tom and mary finally decided to get married .', '<sos> i realized that that box was empty .', '<sos> i haven t forgotten her .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnnofdIM_RDT",
        "outputId": "06daf75b-28e0-451a-cfba-fca34501e347"
      },
      "source": [
        "# Create a tokenizer for the input texts(Spanish) and fit it to them \n",
        "tokenizer_inputs = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
        "tokenizer_inputs.fit_on_texts(input_data)\n",
        "# Tokenize and transform input texts to sequence of integers\n",
        "input_sequences = tokenizer_inputs.texts_to_sequences(input_data)\n",
        "# Claculate the max length\n",
        "input_max_len = max(len(s) for s in input_sequences)\n",
        "print('Max Input Length: ', input_max_len)\n",
        "# Show some example of tokenize sentences, useful to check the tokenization\n",
        "print(input_data[19995])\n",
        "print(input_sequences[19995])\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Input Length:  20\n",
            "no se movio nadie .\n",
            "[4, 15, 3729, 95, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wgcQpCr_iOj",
        "outputId": "eddd2c81-80b3-4091-fc0c-6b9afbb1c963"
      },
      "source": [
        "# tokenize the outputs(English)\n",
        "# don't filter out special characters (filters = '')\n",
        "# otherwise <sos> and <eos> won't appear\n",
        "# By default, Keras’ Tokenizer will trim out all the punctuations, which is not what we want. \n",
        "# we can just set filters as blank here.\n",
        "\n",
        "# Create a tokenizer for the output texts and fit it to them \n",
        "tokenizer_outputs = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
        "tokenizer_outputs.fit_on_texts(target_data)\n",
        "tokenizer_outputs.fit_on_texts(target_input_data)\n",
        "# Tokenize and transform output texts to sequence of integers\n",
        "target_sequences = tokenizer_outputs.texts_to_sequences(target_data)\n",
        "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_input_data)\n",
        "\n",
        "# determine maximum length output sequence\n",
        "target_max_len = max(len(s) for s in target_sequences)\n",
        "print('Max Target Length: ', target_max_len)\n",
        "\n",
        "print(target_data[19995])\n",
        "print(target_sequences[19995])\n",
        "print(target_input_data[19995])\n",
        "print(target_sequences_inputs[19995])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Target Length:  16\n",
            "no one moved . <eos>\n",
            "[70, 74, 902, 1, 2]\n",
            "<sos> no one moved .\n",
            "[3, 70, 74, 902, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyFQ1Uj-BC7_",
        "outputId": "c19d486c-b0b1-4f9f-8038-27cc0d80ba1f"
      },
      "source": [
        "#Creating Vocabularies\n",
        "# get the word to index mapping for input language\n",
        "word2idx_inputs = tokenizer_inputs.word_index\n",
        "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
        "\n",
        "# get the word to index mapping for output language\n",
        "word2idx_outputs = tokenizer_outputs.word_index\n",
        "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
        "\n",
        "# store number of output and input words for later\n",
        "# remember to add 1 since indexing starts at 1\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "num_words_inputs = len(word2idx_inputs) + 1\n",
        "\n",
        "# map indexes back into real words\n",
        "# so we can view the results\n",
        "idx2word_inputs = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_outputs = {v:k for k, v in word2idx_outputs.items()}"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20977 unique input tokens.\n",
            "Found 10944 unique output tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raNa91bmBYyI",
        "outputId": "8d37882b-0e66-402e-ce42-80476405ee30"
      },
      "source": [
        "#Padding - necessary to pad the sentences with 0 at the end so all the sentences have the smae length\n",
        "# pad the input sequences\n",
        "encoder_inputs = pad_sequences(input_sequences, maxlen=input_max_len, padding='post')\n",
        "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n",
        "print(\"encoder_inputs[0]:\", encoder_inputs[0])\n",
        "# pad the decoder input sequences\n",
        "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=target_max_len, padding='post')\n",
        "print(\"decoder_inputs[0]:\", decoder_inputs[0])\n",
        "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n",
        "# pad the target output sequences\n",
        "decoder_targets = pad_sequences(target_sequences, maxlen=target_max_len, padding='post')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder_inputs.shape: (96000, 20)\n",
            "encoder_inputs[0]: [   5   37   28  850 2510 1324    1    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0]\n",
            "decoder_inputs[0]: [  3   8  50  35 721 427   7  67 260   1   0   0   0   0   0   0]\n",
            "decoder_inputs.shape: (96000, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47lub20SBtW6"
      },
      "source": [
        "# Define a dataset \n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (encoder_inputs, decoder_inputs, decoder_targets))\n",
        "dataset = dataset.shuffle(len(input_data)).batch(\n",
        "    BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E8iyHhpB4OK"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # Define the embedding layer\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        # Define the RNN layer, LSTM\n",
        "        self.lstm = tf.keras.layers.LSTM(\n",
        "            hidden_dim, return_sequences=True, return_state=True)\n",
        "\n",
        "    def call(self, input_sequence, states):\n",
        "        # Embed the input\n",
        "        embed = self.embedding(input_sequence)\n",
        "        # Call the LSTM unit\n",
        "        output, state_h, state_c = self.lstm(embed, initial_state=states)\n",
        "\n",
        "        return output, state_h, state_c\n",
        "\n",
        "    def init_states(self, batch_size):\n",
        "        # Return a all 0s initial states\n",
        "        return (tf.zeros([batch_size, self.hidden_dim]),\n",
        "                tf.zeros([batch_size, self.hidden_dim]))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoBdBhckB8YA"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # Define the embedding layer\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        # Define the RNN layer, LSTM\n",
        "        self.lstm = tf.keras.layers.LSTM(\n",
        "            hidden_dim, return_sequences=True, return_state=True)\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, input_sequence, state):\n",
        "        # Embed the input\n",
        "        embed = self.embedding(input_sequence)\n",
        "        # Call the LSTM unit\n",
        "        lstm_out, state_h, state_c = self.lstm(embed, state)\n",
        "        # Dense layer to predict output token\n",
        "        logits = self.dense(lstm_out)\n",
        "\n",
        "        return logits, state_h, state_c"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbvH_DS6CAh1",
        "outputId": "ac0c9c63-4345-473b-d911-ce3700336352"
      },
      "source": [
        "#Set the length of the input and output vocabulary\n",
        "num_words_inputs = len(word2idx_inputs) + 1\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "#Create the encoder\n",
        "encoder = Encoder(num_words_inputs, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "# Get the initial states\n",
        "initial_state = encoder.init_states(1)\n",
        "# Call the encoder for testing\n",
        "test_encoder_output = encoder(tf.constant(\n",
        "    [[1, 23, 4, 5, 0, 0]]), initial_state)\n",
        "print(test_encoder_output[0].shape)\n",
        "# Create the decoder\n",
        "decoder = Decoder(num_words_output, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "# Get the initial states\n",
        "de_initial_state = test_encoder_output[1:]\n",
        "# Call the decoder for testing\n",
        "test_decoder_output = decoder(tf.constant(\n",
        "    [[1, 3, 5, 7, 9, 0, 0, 0]]), de_initial_state)\n",
        "print(test_decoder_output[0].shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 6, 1024)\n",
            "(1, 8, 10945)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oso4D35RCC-N"
      },
      "source": [
        "def loss_func(targets, logits):\n",
        "    crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True)\n",
        "    # Mask padding values, they do not have to compute for loss\n",
        "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "    mask = tf.cast(mask, dtype=tf.int64)\n",
        "    # Calculate the loss value\n",
        "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    # y_pred shape is batch_size, seq length, vocab size\n",
        "    # y_true shape is batch_size, seq length\n",
        "    pred_values = K.cast(K.argmax(y_pred, axis=-1), dtype='int32')\n",
        "    correct = K.cast(K.equal(y_true, pred_values), dtype='float32')\n",
        "\n",
        "    # 0 is padding, don't include those\n",
        "    mask = K.cast(K.greater(y_true, 0), dtype='float32')\n",
        "    n_correct = K.sum(mask * correct)\n",
        "    n_total = K.sum(mask)\n",
        "  \n",
        "    return n_correct / n_total"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwUPWQE7CicV"
      },
      "source": [
        "# Use the @tf.function decorator to take advance of static graph computation\n",
        "@tf.function\n",
        "def train_step(input_seq, target_seq_in, target_seq_out, en_initial_states, optimizer):\n",
        "    ''' A training step, train a batch of the data and return the loss value reached\n",
        "        Input:\n",
        "        - input_seq: array of integers, shape [batch_size, max_seq_len, embedding dim].\n",
        "            the input sequence\n",
        "        - target_seq_out: array of integers, shape [batch_size, max_seq_len, embedding dim].\n",
        "            the target seq, our target sequence\n",
        "        - target_seq_in: array of integers, shape [batch_size, max_seq_len, embedding dim].\n",
        "            the input sequence to the decoder, we use Teacher Forcing\n",
        "        - en_initial_states: tuple of arrays of shape [batch_size, hidden_dim].\n",
        "            the initial state of the encoder\n",
        "        - optimizer: a tf.keras.optimizers.\n",
        "        Output:\n",
        "        - loss: loss value\n",
        "        \n",
        "    '''\n",
        "    # Network’s computations need to be put under tf.GradientTape() to keep track of gradients\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Get the encoder outputs\n",
        "        en_outputs = encoder(input_seq, en_initial_states)\n",
        "        # Set the encoder and decoder states\n",
        "        en_states = en_outputs[1:]\n",
        "        de_states = en_states\n",
        "        # Get the encoder outputs\n",
        "        de_outputs = decoder(target_seq_in, de_states)\n",
        "        # Take the actual output\n",
        "        logits = de_outputs[0]\n",
        "        # Calculate the loss function\n",
        "        loss = loss_func(target_seq_out, logits)\n",
        "        acc = accuracy_fn(target_seq_out, logits)\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    # Calculate the gradients for the variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    # Apply the gradients and update the optimizer\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return loss, acc"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I7p8u-cCnE4"
      },
      "source": [
        "# Create the main train function\n",
        "def main_train(encoder, decoder, dataset, n_epochs, batch_size, optimizer, checkpoint, checkpoint_prefix):\n",
        "    \n",
        "    losses = []\n",
        "    accuracies = []\n",
        "\n",
        "    for e in range(n_epochs):\n",
        "        # Get the initial time\n",
        "        start = time.time()\n",
        "        # Get the initial state for the encoder\n",
        "        en_initial_states = encoder.init_states(batch_size)\n",
        "        # For every batch data\n",
        "        for batch, (input_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
        "            # Train and get the loss value \n",
        "            loss, accuracy = train_step(input_seq, target_seq_in, target_seq_out, en_initial_states, optimizer)\n",
        "        \n",
        "            if batch % 100 == 0:\n",
        "                # Store the loss and accuracy values\n",
        "                losses.append(loss)\n",
        "                accuracies.append(accuracy)\n",
        "                print('Epoch {} Batch {} Loss {:.4f} Acc:{:.4f}'.format(e + 1, batch, loss.numpy(), accuracy.numpy()))\n",
        "                \n",
        "        # saving (checkpoint) the model every 2 epochs\n",
        "        if (e + 1) % 2 == 0:\n",
        "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    \n",
        "        print('Time taken for 1 epoch {:.4f} sec\\n'.format(time.time() - start))\n",
        "        \n",
        "    return losses, accuracies"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e71ApyYqC0Fe",
        "outputId": "74d2f138-3524-4709-9f52-bdc74ccd3629"
      },
      "source": [
        "# Create an Adam optimizer and clips gradients by norm\n",
        "optimizer = tf.keras.optimizers.Adam(clipnorm=5.0)\n",
        "# Create a checkpoint object to save the model\n",
        "checkpoint_dir = '/content/drive/MyDrive/machine-translation/models/spa-eng/training_ckpt_seq2seq'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n",
        "\n",
        "losses, accuracies = main_train(encoder, decoder, dataset, EPOCHS, BATCH_SIZE, optimizer, checkpoint, checkpoint_prefix)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.6415 Acc:0.0000\n",
            "Epoch 1 Batch 100 Loss 2.3900 Acc:0.2817\n",
            "Epoch 1 Batch 200 Loss 2.1493 Acc:0.2995\n",
            "Epoch 1 Batch 300 Loss 2.1080 Acc:0.3242\n",
            "Epoch 1 Batch 400 Loss 1.9340 Acc:0.3732\n",
            "Epoch 1 Batch 500 Loss 1.8414 Acc:0.3710\n",
            "Epoch 1 Batch 600 Loss 1.7714 Acc:0.3794\n",
            "Epoch 1 Batch 700 Loss 1.6927 Acc:0.3862\n",
            "Time taken for 1 epoch 105.7384 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.7889 Acc:0.3851\n",
            "Epoch 2 Batch 100 Loss 1.7638 Acc:0.3832\n",
            "Epoch 2 Batch 200 Loss 1.5989 Acc:0.3897\n",
            "Epoch 2 Batch 300 Loss 1.6811 Acc:0.3990\n",
            "Epoch 2 Batch 400 Loss 1.7086 Acc:0.3898\n",
            "Epoch 2 Batch 500 Loss 1.7565 Acc:0.3915\n",
            "Epoch 2 Batch 600 Loss 1.6338 Acc:0.4223\n",
            "Epoch 2 Batch 700 Loss 1.5318 Acc:0.4238\n",
            "Time taken for 1 epoch 105.5648 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.5467 Acc:0.4200\n",
            "Epoch 3 Batch 100 Loss 1.4642 Acc:0.4662\n",
            "Epoch 3 Batch 200 Loss 1.4752 Acc:0.4577\n",
            "Epoch 3 Batch 300 Loss 1.4620 Acc:0.4638\n",
            "Epoch 3 Batch 400 Loss 1.3383 Acc:0.4935\n",
            "Epoch 3 Batch 500 Loss 1.3900 Acc:0.4844\n",
            "Epoch 3 Batch 600 Loss 1.3527 Acc:0.4895\n",
            "Epoch 3 Batch 700 Loss 1.2894 Acc:0.5029\n",
            "Time taken for 1 epoch 106.0958 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.2281 Acc:0.4985\n",
            "Epoch 4 Batch 100 Loss 1.2252 Acc:0.5144\n",
            "Epoch 4 Batch 200 Loss 1.1588 Acc:0.5408\n",
            "Epoch 4 Batch 300 Loss 1.1660 Acc:0.5221\n",
            "Epoch 4 Batch 400 Loss 1.2153 Acc:0.5153\n",
            "Epoch 4 Batch 500 Loss 1.1485 Acc:0.5473\n",
            "Epoch 4 Batch 600 Loss 1.1735 Acc:0.5360\n",
            "Epoch 4 Batch 700 Loss 1.1817 Acc:0.5303\n",
            "Time taken for 1 epoch 107.5815 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.0768 Acc:0.5727\n",
            "Epoch 5 Batch 100 Loss 1.0637 Acc:0.5540\n",
            "Epoch 5 Batch 200 Loss 1.0714 Acc:0.5642\n",
            "Epoch 5 Batch 300 Loss 1.0650 Acc:0.5764\n",
            "Epoch 5 Batch 400 Loss 0.9961 Acc:0.5672\n",
            "Epoch 5 Batch 500 Loss 0.9712 Acc:0.6059\n",
            "Epoch 5 Batch 600 Loss 1.0324 Acc:0.5899\n",
            "Epoch 5 Batch 700 Loss 0.9304 Acc:0.6145\n",
            "Time taken for 1 epoch 105.9140 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.8856 Acc:0.6103\n",
            "Epoch 6 Batch 100 Loss 0.9026 Acc:0.6171\n",
            "Epoch 6 Batch 200 Loss 0.9366 Acc:0.6059\n",
            "Epoch 6 Batch 300 Loss 0.8614 Acc:0.6380\n",
            "Epoch 6 Batch 400 Loss 0.8391 Acc:0.6242\n",
            "Epoch 6 Batch 500 Loss 0.8771 Acc:0.6338\n",
            "Epoch 6 Batch 600 Loss 0.8593 Acc:0.6280\n",
            "Epoch 6 Batch 700 Loss 0.8600 Acc:0.6365\n",
            "Time taken for 1 epoch 106.5668 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.7995 Acc:0.6468\n",
            "Epoch 7 Batch 100 Loss 0.7752 Acc:0.6616\n",
            "Epoch 7 Batch 200 Loss 0.7697 Acc:0.6702\n",
            "Epoch 7 Batch 300 Loss 0.7659 Acc:0.6547\n",
            "Epoch 7 Batch 400 Loss 0.7808 Acc:0.6428\n",
            "Epoch 7 Batch 500 Loss 0.7076 Acc:0.6757\n",
            "Epoch 7 Batch 600 Loss 0.7718 Acc:0.6382\n",
            "Epoch 7 Batch 700 Loss 0.7912 Acc:0.6513\n",
            "Time taken for 1 epoch 106.3507 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.6045 Acc:0.7097\n",
            "Epoch 8 Batch 100 Loss 0.5894 Acc:0.7098\n",
            "Epoch 8 Batch 200 Loss 0.6093 Acc:0.7320\n",
            "Epoch 8 Batch 300 Loss 0.6027 Acc:0.7271\n",
            "Epoch 8 Batch 400 Loss 0.6259 Acc:0.7079\n",
            "Epoch 8 Batch 500 Loss 0.6858 Acc:0.6971\n",
            "Epoch 8 Batch 600 Loss 0.6152 Acc:0.7143\n",
            "Epoch 8 Batch 700 Loss 0.6445 Acc:0.7082\n",
            "Time taken for 1 epoch 108.5804 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.4937 Acc:0.7714\n",
            "Epoch 9 Batch 100 Loss 0.4924 Acc:0.7624\n",
            "Epoch 9 Batch 200 Loss 0.5888 Acc:0.7267\n",
            "Epoch 9 Batch 300 Loss 0.5557 Acc:0.7383\n",
            "Epoch 9 Batch 400 Loss 0.4985 Acc:0.7503\n",
            "Epoch 9 Batch 500 Loss 0.5635 Acc:0.7336\n",
            "Epoch 9 Batch 600 Loss 0.5365 Acc:0.7440\n",
            "Epoch 9 Batch 700 Loss 0.5531 Acc:0.7350\n",
            "Time taken for 1 epoch 107.1497 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.3769 Acc:0.7990\n",
            "Epoch 10 Batch 100 Loss 0.4526 Acc:0.7727\n",
            "Epoch 10 Batch 200 Loss 0.4562 Acc:0.7881\n",
            "Epoch 10 Batch 300 Loss 0.4761 Acc:0.7630\n",
            "Epoch 10 Batch 400 Loss 0.4368 Acc:0.8008\n",
            "Epoch 10 Batch 500 Loss 0.4713 Acc:0.7666\n",
            "Epoch 10 Batch 600 Loss 0.4396 Acc:0.7776\n",
            "Epoch 10 Batch 700 Loss 0.4625 Acc:0.7865\n",
            "Time taken for 1 epoch 107.4916 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "ATeh7SnuC-OY",
        "outputId": "ab53a1dc-9aee-4b11-c138-ab1dbe54bc75"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
        "# plot some data\n",
        "ax1.plot(losses, label='loss')\n",
        "#plt.plot(results.history['val_loss'], label='val_loss')\n",
        "ax1.set_title('Training Loss')\n",
        "ax1.legend()\n",
        "# accuracies\n",
        "ax2.plot(accuracies, label='acc')\n",
        "#plt.plot(results.history['val_accuracy_fn'], label='val_acc')\n",
        "ax2.set_title('Training Accuracy')\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKDN5aJJDBa8"
      },
      "source": [
        "# Create an Adam optimizer and clips gradients by norm\n",
        "optimizer = tf.keras.optimizers.Adam(clipnorm=5.0)\n",
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint_dir = '/content/drive/MyDrive/machine-translation/models/spa-eng/training_ckpt_seq2seq'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfGDndYittjS"
      },
      "source": [
        "predicted_list = []"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT8GxJv1DNzw"
      },
      "source": [
        "def predict(input_text, encoder, input_max_len, tokenizer_inputs, word2idx_outputs, idx2word_outputs):\n",
        "    if input_text is None:\n",
        "        input_text = input_data[np.random.choice(len(input_data))]\n",
        "        #print(input_text)\n",
        "    # Tokenize the input sequence\n",
        "    input_seq = tokenizer_inputs.texts_to_sequences([input_text])\n",
        "    # Pad the sentence\n",
        "    input_seq = pad_sequences(input_seq, maxlen=input_max_len, padding='post')\n",
        "    #print(input_seq)\n",
        "    # Set the encoder initial state\n",
        "    en_initial_states = encoder.init_states(1)\n",
        "    en_outputs = encoder(tf.constant(input_seq), en_initial_states)\n",
        "    # Create the decoder input, the sos token\n",
        "    de_input = tf.constant([[word2idx_outputs['<sos>']]])\n",
        "    # Set the decoder states to the encoder vector or encoder hidden state\n",
        "    de_state_h, de_state_c = en_outputs[1:]\n",
        "    \n",
        "    out_words = []\n",
        "    while True:\n",
        "        # Decode and get the output probabilities\n",
        "        de_output, de_state_h, de_state_c = decoder(\n",
        "            de_input, (de_state_h, de_state_c))\n",
        "        # Select the word with the highest probability\n",
        "        de_input = tf.argmax(de_output, -1)\n",
        "        # Append the word to the predicted output\n",
        "        out_words.append(idx2word_outputs[de_input.numpy()[0][0]])\n",
        "        # Finish when eos token is found or the max length is reached\n",
        "        if out_words[-1] == '<eos>' or len(out_words) >= 20:\n",
        "            break\n",
        "    out_words = ' '.join(out_words)\n",
        "    predicted_list.append(out_words)\n",
        "    #print('Predicted English Text - ',' '.join(out_words))\n",
        "    return predicted_list"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLLeNBt01A2W",
        "outputId": "5118f895-a5f2-44af-a80d-9743209cfcbb"
      },
      "source": [
        "# Preprocess the input data\n",
        "input_data_test = test[INPUT_COLUMN].apply(lambda x : preprocess_sentence(x)).tolist()\n",
        "# Preprocess and include the end of sentence token to the target text\n",
        "target_data_test = test[TARGET_COLUMN].apply(lambda x : preprocess_sentence(x)+ ' <eos>').tolist()\n",
        "# Preprocess and include a start of setence token to the input text to the decoder, it is right shifted\n",
        "target_input_data_test = test[TARGET_COLUMN].apply(lambda x : '<sos> '+ preprocess_sentence(x)).tolist()\n",
        "print(input_data_test[:10])\n",
        "print(target_data_test[:10])\n",
        "print(target_input_data_test[:10])\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['¿ no puedes decidirte ?', 'tomas le ofrecio una copa de vino a maria .', 'el tambien puede hablar ruso .', 'he estado tratando de captar tu atencion .', '¿ te gusta esta cancion ?', 'esta habitacion tiene tres ventanas .', 'aqui tienes los documentos que pediste .', 'me gusta esta taza .', 'alguien la visito ayer .', '¿ lo recuerdas ?']\n",
            "['can t you make up your mind ? <eos>', 'tom offered mary a glass of wine . <eos>', 'he can speak russian as well . <eos>', 'i ve been trying to get your attention . <eos>', 'do you like that song ? <eos>', 'this room has three windows . <eos>', 'here are the documents you asked for . <eos>', 'i like this cup . <eos>', 'someone visited her yesterday . <eos>', 'do you remember ? <eos>']\n",
            "['<sos> can t you make up your mind ?', '<sos> tom offered mary a glass of wine .', '<sos> he can speak russian as well .', '<sos> i ve been trying to get your attention .', '<sos> do you like that song ?', '<sos> this room has three windows .', '<sos> here are the documents you asked for .', '<sos> i like this cup .', '<sos> someone visited her yesterday .', '<sos> do you remember ?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trS8IIEvDS9M",
        "outputId": "b65f3868-04df-4ed8-b157-fb85dcb63d15"
      },
      "source": [
        "#zipped_list = list(zip(input_data_test, target_data_test))\n",
        "#test_sent = random.sample(zipped_list, 20)\n",
        "#for test_sent in test_sent:\n",
        " #   print('Input Spanish Text - ', test_sent)\n",
        " #   predict(test_sent, encoder, input_max_len, tokenizer_inputs, word2idx_outputs, idx2word_outputs)\n",
        " #   print('\\n')\n",
        "#print(len(input_data_test))\n",
        "\n",
        "for test_sent, test_output in zip(input_data_test[:10], target_data_test[:10]):\n",
        "    print('Input Spanish Text - ', test_sent)\n",
        "    print('Target English Text - ', test_output)\n",
        "    predict(test_sent, encoder, input_max_len, tokenizer_inputs, word2idx_outputs, idx2word_outputs)\n",
        "    print('\\n')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Spanish Text -  ¿ no puedes decidirte ?\n",
            "Target English Text -  can t you make up your mind ? <eos>\n",
            "\n",
            "\n",
            "Input Spanish Text -  tomas le ofrecio una copa de vino a maria .\n",
            "Target English Text -  tom offered mary a glass of wine . <eos>\n",
            "\n",
            "\n",
            "Input Spanish Text -  el tambien puede hablar ruso .\n",
            "Target English Text -  he can speak russian as well . <eos>\n",
            "\n",
            "\n",
            "Input Spanish Text -  he estado tratando de captar tu atencion .\n",
            "Target English Text -  i ve been trying to get your attention . <eos>\n",
            "\n",
            "\n",
            "Input Spanish Text -  ¿ te gusta esta cancion ?\n",
            "Target English Text -  do you like that song ? <eos>\n",
            "\n",
            "\n",
            "Input Spanish Text -  esta habitacion tiene tres ventanas .\n",
            "Target English Text -  this room has three windows . <eos>\n",
            "\n",
            "\n",
            "Input Spanish Text -  aqui tienes los documentos que pediste .\n",
            "Target English Text -  here are the documents you asked for . <eos>\n",
            "\n",
            "\n",
            "Input Spanish Text -  me gusta esta taza .\n",
            "Target English Text -  i like this cup . <eos>\n",
            "\n",
            "\n",
            "Input Spanish Text -  alguien la visito ayer .\n",
            "Target English Text -  someone visited her yesterday . <eos>\n",
            "\n",
            "\n",
            "Input Spanish Text -  ¿ lo recuerdas ?\n",
            "Target English Text -  do you remember ? <eos>\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNvaTbvftzZV",
        "outputId": "2041c53d-9d82-454f-9f35-9d578d09f758"
      },
      "source": [
        "predicted_list"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN3S1XFOswZM"
      },
      "source": [
        "for test_sent, test_output in zip(input_data_test[:10000], target_data_test[:10000]):\n",
        "    predict(test_sent, encoder, input_max_len, tokenizer_inputs, word2idx_outputs, idx2word_outputs)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVbu5HotuOQB",
        "outputId": "71c208ae-274e-408f-be44-492aeb322c2a"
      },
      "source": [
        "print(len(predicted_list))\n",
        "predicted_list[:10]"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['can t you lift it ? <eos>',\n",
              " 'tom offered mary a present . <eos>',\n",
              " 'he can swim , but i don t . <eos>',\n",
              " 'i ve been trying to get you all . <eos>',\n",
              " 'do you like this garden ? <eos>',\n",
              " 'this room has three rooms . <eos>',\n",
              " 'you have only one of your own mind . <eos>',\n",
              " 'i like this movie . <eos>',\n",
              " 'somebody knocked on the door . <eos>',\n",
              " 'do you remember me ? <eos>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzYpaHvUyeuE",
        "outputId": "c86ef2f6-1a99-46d9-c9ff-afdaeeb852a8"
      },
      "source": [
        "print(len(target_data_test))\n",
        "target_data_test[:10]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['can t you make up your mind ? <eos>',\n",
              " 'tom offered mary a glass of wine . <eos>',\n",
              " 'he can speak russian as well . <eos>',\n",
              " 'i ve been trying to get your attention . <eos>',\n",
              " 'do you like that song ? <eos>',\n",
              " 'this room has three windows . <eos>',\n",
              " 'here are the documents you asked for . <eos>',\n",
              " 'i like this cup . <eos>',\n",
              " 'someone visited her yesterday . <eos>',\n",
              " 'do you remember ? <eos>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx-UYTe--WFQ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgpFiTqHI-Qw"
      },
      "source": [
        "#BLEU SCORE using our own function\n",
        "#Bleu = Brevity Penalty * precision\n",
        "def brevity_penalty(reference, candidate):\n",
        "    ref_length = len(reference)\n",
        "    can_length = len(candidate)\n",
        "\n",
        "    # Brevity Penalty\n",
        "    if ref_length > can_length:\n",
        "        BP = 1\n",
        "    else:\n",
        "        penalty = 1 - (ref_length / can_length)\n",
        "        BP = np.exp(penalty)\n",
        "\n",
        "    return BP"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-Ok7rpEkXAm"
      },
      "source": [
        "def clipped_precision(reference, candidate):\n",
        "    \"\"\"\n",
        "    Bleu score function given a original and a machine translated sentences\n",
        "    \"\"\"\n",
        "\n",
        "    clipped_precision_score = []\n",
        "\n",
        "    for i in range(1, 5):\n",
        "        candidate_n_gram = Counter(\n",
        "            ngrams(candidate, i)\n",
        "        )  # counts of n-gram n=1...4 tokens for the candidate\n",
        "        reference_n_gram = Counter(\n",
        "            ngrams(reference, i)\n",
        "        )  # counts of n-gram n=1...4 tokens for the reference\n",
        "\n",
        "        c = sum(\n",
        "            reference_n_gram.values()\n",
        "        )  # sum of the values of the reference the denominator in the precision formula\n",
        "\n",
        "        for j in reference_n_gram:  # for every n_gram token in the reference\n",
        "            if j in candidate_n_gram:  # check if it is in the candidate n-gram\n",
        "\n",
        "                if (\n",
        "                    reference_n_gram[j] > candidate_n_gram[j]\n",
        "                ):  # if the count of the reference n-gram is bigger\n",
        "                    # than the corresponding count in the candidate n-gram\n",
        "                    reference_n_gram[j] = candidate_n_gram[\n",
        "                        j\n",
        "                    ]  # then set the count of the reference n-gram to be equal\n",
        "                    # to the count of the candidate n-gram\n",
        "            else:\n",
        "\n",
        "                reference_n_gram[j] = 0  # else reference n-gram = 0\n",
        "\n",
        "        clipped_precision_score.append(sum(reference_n_gram.values()) / c)\n",
        "\n",
        "    weights = [0.25] * 4\n",
        "\n",
        "    s = (w_i * np.log(p_i) for w_i, p_i in zip(weights, clipped_precision_score))\n",
        "    s = np.exp(np.sum(s))\n",
        "    return s"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zegfgt1vn6OK"
      },
      "source": [
        "def bleu_score(reference, candidate):\n",
        "    BP = brevity_penalty(reference, candidate)\n",
        "    precision = clipped_precision(reference, candidate)\n",
        "    return BP * precision"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSvSKzK_n9jv",
        "outputId": "491e3f52-dbfa-410f-850a-182c9245a872"
      },
      "source": [
        "#Word Tokenizing every element in the reference and candidate list\n",
        "bleu = []\n",
        "for tokenized_ref, tokenized_can in zip(target_data_test[:10000], predicted_list): \n",
        "    score = round(bleu_score(tokenized_ref, tokenized_can) * 100, 1)\n",
        "    bleu.append(score)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3eVWEp7y4jH",
        "outputId": "38f2e71f-a74e-4bd0-af11-a35b36fde0bc"
      },
      "source": [
        "statistics.mean(bleu)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58.86159"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS_U9bMc9r-i"
      },
      "source": [
        "#SacreBleu Score\n",
        "#Word Tokenizing every element in the reference and candidate list\n",
        "bleu_score = []\n",
        "for tokenized_ref, tokenized_can in zip(target_data_test, predicted_list): \n",
        "    score = round(sacrebleu.corpus_bleu(tokenized_ref, tokenized_can).score, 1)\n",
        "    bleu_score.append(score)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6jzl-b3_VKp",
        "outputId": "1e5408f5-a7d3-4499-8f37-4cac48463fbc"
      },
      "source": [
        "statistics.mean(bleu_score)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40.659"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3eeq6ViAIB5",
        "outputId": "e8d3d8f4-1a8e-49cf-becc-39a14d6fb961"
      },
      "source": [
        "#Not sure if correct. might have some error\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "nltk_bleu_score = []\n",
        "for tokenized_ref, tokenized_can in zip(target_data_test, predicted_list): \n",
        "    score = sentence_bleu(tokenized_ref, tokenized_can)\n",
        "    nltk_bleu_score.append(score)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGN8isgEBw__",
        "outputId": "a768a09f-4f20-4931-deb5-94bc38a31882"
      },
      "source": [
        "statistics.mean(nltk_bleu_score)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8093876948110793"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0wMuA2YB2dJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}