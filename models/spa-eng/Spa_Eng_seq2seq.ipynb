{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spa-Eng-seq2seq.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdundVLN9uuC",
        "outputId": "f407350c-fc71-4b5d-8a4c-f3e4dc0fb4f2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeaRh5cM-gx_"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import time\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjXcgTN5-y9G"
      },
      "source": [
        "# Global parameters\n",
        "#root folder\n",
        "root_folder='/content/drive/MyDrive/machine-translation/'\n",
        "#data_folder='.'\n",
        "data_folder_name='corpus/spa-eng'\n",
        "train_filename='spa.txt'\n",
        "\n",
        "# Variable for data directory\n",
        "DATA_PATH = os.path.abspath(os.path.join(root_folder, data_folder_name))\n",
        "train_filenamepath = os.path.abspath(os.path.join(DATA_PATH, train_filename))\n",
        "\n",
        "# Both train and test set are in the root data directory\n",
        "train_path = DATA_PATH\n",
        "test_path = DATA_PATH"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9s6USIkr-1IH",
        "outputId": "286a8f43-5b5b-4aa5-fc07-ff94e59dfbc6"
      },
      "source": [
        "train_filenamepath"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/machine-translation/corpus/spa-eng/spa.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCUFwsvK-2fV"
      },
      "source": [
        "# Parameters for our model\n",
        "INPUT_COLUMN = 'input'\n",
        "TARGET_COLUMN = 'target'\n",
        "TARGET_FOR_INPUT = 'target_for_input'\n",
        "NUM_SAMPLES = 100000 #40000\n",
        "MAX_VOCAB_SIZE = 20000\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 1024 #512\n",
        "\n",
        "BATCH_SIZE = 128  # Batch size for training.\n",
        "EPOCHS = 20  # Number of epochs to train for.\n",
        "\n",
        "ATTENTION_FUNC='general'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEXwZbzO_EQ_"
      },
      "source": [
        "#Preprocessing the data\n",
        "# Some function to preprocess the text data, taken from the Neural machine translation with attention tutorial in Tensorflow\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    ''' Preprocess the input text w applying lowercase, removing accents, \n",
        "    creating a space between a word and the punctuation following it and \n",
        "    replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    Input:\n",
        "        - w: a string, input text\n",
        "    Output:\n",
        "        - a string, the cleaned text\n",
        "    '''\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.strip()\n",
        "\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    #w = '<start> ' + w + ' <end>'\n",
        "    \n",
        "    return w"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEVxX1XF_KVX",
        "outputId": "940b1a4d-bb37-4c9b-e652-be57c9074ef7"
      },
      "source": [
        "# Load the dataset: sentence in english, sentence in spanish \n",
        "df=pd.read_csv(train_filenamepath, sep=\"\\t\", header=None, names=[TARGET_COLUMN,INPUT_COLUMN], usecols=[0,1], \n",
        "               nrows=NUM_SAMPLES)\n",
        "# Preprocess the input data\n",
        "input_data=df[INPUT_COLUMN].apply(lambda x : preprocess_sentence(x)).tolist()\n",
        "# Preprocess and include the end of sentence token to the target text\n",
        "target_data=df[TARGET_COLUMN].apply(lambda x : preprocess_sentence(x)+ ' <eos>').tolist()\n",
        "# Preprocess and include a start of setence token to the input text to the decoder, it is rigth shifted\n",
        "target_input_data=df[TARGET_COLUMN].apply(lambda x : '<sos> '+ preprocess_sentence(x)).tolist()\n",
        "\n",
        "print(input_data[:5])\n",
        "print(target_data[:5])\n",
        "print(target_input_data[:5])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ve .', 'vete .', 'vaya .', 'vayase .', 'hola .']\n",
            "['go . <eos>', 'go . <eos>', 'go . <eos>', 'go . <eos>', 'hi . <eos>']\n",
            "['<sos> go .', '<sos> go .', '<sos> go .', '<sos> go .', '<sos> hi .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "zc7WSyWC_Oaf",
        "outputId": "40e38803-81ca-46d1-aaf1-fc0e79ffb9e9"
      },
      "source": [
        "df"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>input</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Ve.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vete.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vaya.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Váyase.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Hola.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>I can't see very well without glasses.</td>\n",
              "      <td>No veo muy bien sin gafas.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>I can't see very well without glasses.</td>\n",
              "      <td>No puedo ver muy bien sin gafas.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>I can't stop thinking about yesterday.</td>\n",
              "      <td>No puedo dejar de pensar en lo de ayer.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>I can't tell if you're serious or not.</td>\n",
              "      <td>Yo no puedo decir si tú eres serio o no.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>I can't think of anything else to say.</td>\n",
              "      <td>No se me ocurre nada más que decir.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       target                                     input\n",
              "0                                         Go.                                       Ve.\n",
              "1                                         Go.                                     Vete.\n",
              "2                                         Go.                                     Vaya.\n",
              "3                                         Go.                                   Váyase.\n",
              "4                                         Hi.                                     Hola.\n",
              "...                                       ...                                       ...\n",
              "99995  I can't see very well without glasses.                No veo muy bien sin gafas.\n",
              "99996  I can't see very well without glasses.          No puedo ver muy bien sin gafas.\n",
              "99997  I can't stop thinking about yesterday.   No puedo dejar de pensar en lo de ayer.\n",
              "99998  I can't tell if you're serious or not.  Yo no puedo decir si tú eres serio o no.\n",
              "99999  I can't think of anything else to say.       No se me ocurre nada más que decir.\n",
              "\n",
              "[100000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnnofdIM_RDT",
        "outputId": "cffc3b08-4ee2-4b91-e8ba-a8525645dee4"
      },
      "source": [
        "# Create a tokenizer for the input texts(Spanish) and fit it to them \n",
        "tokenizer_inputs = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
        "tokenizer_inputs.fit_on_texts(input_data)\n",
        "# Tokenize and transform input texts to sequence of integers\n",
        "input_sequences = tokenizer_inputs.texts_to_sequences(input_data)\n",
        "# Claculate the max length\n",
        "input_max_len = max(len(s) for s in input_sequences)\n",
        "print('Max Input Length: ', input_max_len)\n",
        "# Show some example of tokenize sentences, useful to check the tokenization\n",
        "print(input_data[19995])\n",
        "print(input_sequences[19995])\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Input Length:  20\n",
            "¿ hay un problema ?\n",
            "[6, 64, 12, 165, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wgcQpCr_iOj",
        "outputId": "99ddfd22-76d3-4c5f-e54b-54d4080e9ae6"
      },
      "source": [
        "# tokenize the outputs(English)\n",
        "# don't filter out special characters (filters = '')\n",
        "# otherwise <sos> and <eos> won't appear\n",
        "# By default, Keras’ Tokenizer will trim out all the punctuations, which is not what we want. \n",
        "# we can just set filters as blank here.\n",
        "\n",
        "# Create a tokenizer for the output texts and fit it to them \n",
        "tokenizer_outputs = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
        "tokenizer_outputs.fit_on_texts(target_data)\n",
        "tokenizer_outputs.fit_on_texts(target_input_data)\n",
        "# Tokenize and transform output texts to sequence of integers\n",
        "target_sequences = tokenizer_outputs.texts_to_sequences(target_data)\n",
        "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_input_data)\n",
        "\n",
        "# determine maximum length output sequence\n",
        "target_max_len = max(len(s) for s in target_sequences)\n",
        "print('Max Target Length: ', target_max_len)\n",
        "\n",
        "print(target_data[19995])\n",
        "print(target_sequences[19995])\n",
        "print(target_input_data[19995])\n",
        "print(target_sequences_inputs[19995])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Target Length:  14\n",
            "is there a problem ? <eos>\n",
            "[11, 50, 10, 223, 9, 2]\n",
            "<sos> is there a problem ?\n",
            "[3, 11, 50, 10, 223, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyFQ1Uj-BC7_",
        "outputId": "e4522eb4-1c94-4e05-b356-51d7712b3206"
      },
      "source": [
        "#Creating Vocabularies\n",
        "# get the word to index mapping for input language\n",
        "word2idx_inputs = tokenizer_inputs.word_index\n",
        "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
        "\n",
        "# get the word to index mapping for output language\n",
        "word2idx_outputs = tokenizer_outputs.word_index\n",
        "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
        "\n",
        "# store number of output and input words for later\n",
        "# remember to add 1 since indexing starts at 1\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "num_words_inputs = len(word2idx_inputs) + 1\n",
        "\n",
        "# map indexes back into real words\n",
        "# so we can view the results\n",
        "idx2word_inputs = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_outputs = {v:k for k, v in word2idx_outputs.items()}"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20025 unique input tokens.\n",
            "Found 10333 unique output tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raNa91bmBYyI",
        "outputId": "4e760716-826f-44cb-acd8-01b9329e4bf7"
      },
      "source": [
        "#Padding - necessary to pad the sentences with 0 at the end so all the sentences have the smae length\n",
        "# pad the input sequences\n",
        "encoder_inputs = pad_sequences(input_sequences, maxlen=input_max_len, padding='post')\n",
        "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n",
        "print(\"encoder_inputs[0]:\", encoder_inputs[0])\n",
        "# pad the decoder input sequences\n",
        "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=target_max_len, padding='post')\n",
        "print(\"decoder_inputs[0]:\", decoder_inputs[0])\n",
        "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n",
        "# pad the target output sequences\n",
        "decoder_targets = pad_sequences(target_sequences, maxlen=target_max_len, padding='post')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder_inputs.shape: (100000, 20)\n",
            "encoder_inputs[0]: [281   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0]\n",
            "decoder_inputs[0]: [ 3 46  1  0  0  0  0  0  0  0  0  0  0  0]\n",
            "decoder_inputs.shape: (100000, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47lub20SBtW6"
      },
      "source": [
        "# Define a dataset \n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (encoder_inputs, decoder_inputs, decoder_targets))\n",
        "dataset = dataset.shuffle(len(input_data)).batch(\n",
        "    BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E8iyHhpB4OK"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # Define the embedding layer\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        # Define the RNN layer, LSTM\n",
        "        self.lstm = tf.keras.layers.LSTM(\n",
        "            hidden_dim, return_sequences=True, return_state=True)\n",
        "\n",
        "    def call(self, input_sequence, states):\n",
        "        # Embed the input\n",
        "        embed = self.embedding(input_sequence)\n",
        "        # Call the LSTM unit\n",
        "        output, state_h, state_c = self.lstm(embed, initial_state=states)\n",
        "\n",
        "        return output, state_h, state_c\n",
        "\n",
        "    def init_states(self, batch_size):\n",
        "        # Return a all 0s initial states\n",
        "        return (tf.zeros([batch_size, self.hidden_dim]),\n",
        "                tf.zeros([batch_size, self.hidden_dim]))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoBdBhckB8YA"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # Define the embedding layer\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        # Define the RNN layer, LSTM\n",
        "        self.lstm = tf.keras.layers.LSTM(\n",
        "            hidden_dim, return_sequences=True, return_state=True)\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, input_sequence, state):\n",
        "        # Embed the input\n",
        "        embed = self.embedding(input_sequence)\n",
        "        # Call the LSTM unit\n",
        "        lstm_out, state_h, state_c = self.lstm(embed, state)\n",
        "        # Dense layer to predict output token\n",
        "        logits = self.dense(lstm_out)\n",
        "\n",
        "        return logits, state_h, state_c"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbvH_DS6CAh1",
        "outputId": "c0bb69cf-a80d-4e51-eec2-f76dd5100674"
      },
      "source": [
        "#Set the length of the input and output vocabulary\n",
        "num_words_inputs = len(word2idx_inputs) + 1\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "#Create the encoder\n",
        "encoder = Encoder(num_words_inputs, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "# Get the initial states\n",
        "initial_state = encoder.init_states(1)\n",
        "# Call the encoder for testing\n",
        "test_encoder_output = encoder(tf.constant(\n",
        "    [[1, 23, 4, 5, 0, 0]]), initial_state)\n",
        "print(test_encoder_output[0].shape)\n",
        "# Create the decoder\n",
        "decoder = Decoder(num_words_output, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "# Get the initial states\n",
        "de_initial_state = test_encoder_output[1:]\n",
        "# Call the decoder for testing\n",
        "test_decoder_output = decoder(tf.constant(\n",
        "    [[1, 3, 5, 7, 9, 0, 0, 0]]), de_initial_state)\n",
        "print(test_decoder_output[0].shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 6, 1024)\n",
            "(1, 8, 10334)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oso4D35RCC-N"
      },
      "source": [
        "def loss_func(targets, logits):\n",
        "    crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True)\n",
        "    # Mask padding values, they do not have to compute for loss\n",
        "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "    mask = tf.cast(mask, dtype=tf.int64)\n",
        "    # Calculate the loss value\n",
        "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    # y_pred shape is batch_size, seq length, vocab size\n",
        "    # y_true shape is batch_size, seq length\n",
        "    pred_values = K.cast(K.argmax(y_pred, axis=-1), dtype='int32')\n",
        "    correct = K.cast(K.equal(y_true, pred_values), dtype='float32')\n",
        "\n",
        "    # 0 is padding, don't include those\n",
        "    mask = K.cast(K.greater(y_true, 0), dtype='float32')\n",
        "    n_correct = K.sum(mask * correct)\n",
        "    n_total = K.sum(mask)\n",
        "  \n",
        "    return n_correct / n_total"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwUPWQE7CicV"
      },
      "source": [
        "# Use the @tf.function decorator to take advance of static graph computation\n",
        "@tf.function\n",
        "def train_step(input_seq, target_seq_in, target_seq_out, en_initial_states, optimizer):\n",
        "    ''' A training step, train a batch of the data and return the loss value reached\n",
        "        Input:\n",
        "        - input_seq: array of integers, shape [batch_size, max_seq_len, embedding dim].\n",
        "            the input sequence\n",
        "        - target_seq_out: array of integers, shape [batch_size, max_seq_len, embedding dim].\n",
        "            the target seq, our target sequence\n",
        "        - target_seq_in: array of integers, shape [batch_size, max_seq_len, embedding dim].\n",
        "            the input sequence to the decoder, we use Teacher Forcing\n",
        "        - en_initial_states: tuple of arrays of shape [batch_size, hidden_dim].\n",
        "            the initial state of the encoder\n",
        "        - optimizer: a tf.keras.optimizers.\n",
        "        Output:\n",
        "        - loss: loss value\n",
        "        \n",
        "    '''\n",
        "    # Network’s computations need to be put under tf.GradientTape() to keep track of gradients\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Get the encoder outputs\n",
        "        en_outputs = encoder(input_seq, en_initial_states)\n",
        "        # Set the encoder and decoder states\n",
        "        en_states = en_outputs[1:]\n",
        "        de_states = en_states\n",
        "        # Get the encoder outputs\n",
        "        de_outputs = decoder(target_seq_in, de_states)\n",
        "        # Take the actual output\n",
        "        logits = de_outputs[0]\n",
        "        # Calculate the loss function\n",
        "        loss = loss_func(target_seq_out, logits)\n",
        "        acc = accuracy_fn(target_seq_out, logits)\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    # Calculate the gradients for the variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    # Apply the gradients and update the optimizer\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return loss, acc"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I7p8u-cCnE4"
      },
      "source": [
        "# Create the main train function\n",
        "def main_train(encoder, decoder, dataset, n_epochs, batch_size, optimizer, checkpoint, checkpoint_prefix):\n",
        "    \n",
        "    losses = []\n",
        "    accuracies = []\n",
        "\n",
        "    for e in range(n_epochs):\n",
        "        # Get the initial time\n",
        "        start = time.time()\n",
        "        # Get the initial state for the encoder\n",
        "        en_initial_states = encoder.init_states(batch_size)\n",
        "        # For every batch data\n",
        "        for batch, (input_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
        "            # Train and get the loss value \n",
        "            loss, accuracy = train_step(input_seq, target_seq_in, target_seq_out, en_initial_states, optimizer)\n",
        "        \n",
        "            if batch % 100 == 0:\n",
        "                # Store the loss and accuracy values\n",
        "                losses.append(loss)\n",
        "                accuracies.append(accuracy)\n",
        "                print('Epoch {} Batch {} Loss {:.4f} Acc:{:.4f}'.format(e + 1, batch, loss.numpy(), accuracy.numpy()))\n",
        "                \n",
        "        # saving (checkpoint) the model every 2 epochs\n",
        "        if (e + 1) % 2 == 0:\n",
        "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    \n",
        "        print('Time taken for 1 epoch {:.4f} sec\\n'.format(time.time() - start))\n",
        "        \n",
        "    return losses, accuracies"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e71ApyYqC0Fe",
        "outputId": "faa368df-0e7f-4361-e2b6-c3c9699f2438"
      },
      "source": [
        "# Create an Adam optimizer and clips gradients by norm\n",
        "optimizer = tf.keras.optimizers.Adam(clipnorm=5.0)\n",
        "# Create a checkpoint object to save the model\n",
        "checkpoint_dir = '/content/drive/MyDrive/machine-translation/models/spa-eng/training_ckpt_seq2seq'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n",
        "\n",
        "losses, accuracies = main_train(encoder, decoder, dataset, EPOCHS, BATCH_SIZE, optimizer, checkpoint, checkpoint_prefix)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.9619 Acc:0.0000\n",
            "Epoch 1 Batch 100 Loss 2.4552 Acc:0.3007\n",
            "Epoch 1 Batch 200 Loss 2.2804 Acc:0.3186\n",
            "Epoch 1 Batch 300 Loss 2.0306 Acc:0.3700\n",
            "Epoch 1 Batch 400 Loss 2.1268 Acc:0.3613\n",
            "Epoch 1 Batch 500 Loss 1.9255 Acc:0.3900\n",
            "Epoch 1 Batch 600 Loss 1.8468 Acc:0.4056\n",
            "Epoch 1 Batch 700 Loss 1.7278 Acc:0.4387\n",
            "Time taken for 1 epoch 79.7817 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.7063 Acc:0.4519\n",
            "Epoch 2 Batch 100 Loss 1.6150 Acc:0.4586\n",
            "Epoch 2 Batch 200 Loss 1.5352 Acc:0.4771\n",
            "Epoch 2 Batch 300 Loss 1.5399 Acc:0.4852\n",
            "Epoch 2 Batch 400 Loss 1.4996 Acc:0.4894\n",
            "Epoch 2 Batch 500 Loss 1.5496 Acc:0.4781\n",
            "Epoch 2 Batch 600 Loss 1.4517 Acc:0.5021\n",
            "Epoch 2 Batch 700 Loss 1.3808 Acc:0.5124\n",
            "Time taken for 1 epoch 77.2721 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.3096 Acc:0.5069\n",
            "Epoch 3 Batch 100 Loss 1.2552 Acc:0.5304\n",
            "Epoch 3 Batch 200 Loss 1.3219 Acc:0.5513\n",
            "Epoch 3 Batch 300 Loss 1.2760 Acc:0.5361\n",
            "Epoch 3 Batch 400 Loss 1.1697 Acc:0.5675\n",
            "Epoch 3 Batch 500 Loss 1.1905 Acc:0.5655\n",
            "Epoch 3 Batch 600 Loss 1.2795 Acc:0.5397\n",
            "Epoch 3 Batch 700 Loss 1.2352 Acc:0.5569\n",
            "Time taken for 1 epoch 76.1544 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.1424 Acc:0.5545\n",
            "Epoch 4 Batch 100 Loss 1.0637 Acc:0.5803\n",
            "Epoch 4 Batch 200 Loss 1.0831 Acc:0.5803\n",
            "Epoch 4 Batch 300 Loss 1.1211 Acc:0.5805\n",
            "Epoch 4 Batch 400 Loss 1.1284 Acc:0.5669\n",
            "Epoch 4 Batch 500 Loss 1.0993 Acc:0.5914\n",
            "Epoch 4 Batch 600 Loss 1.0770 Acc:0.5975\n",
            "Epoch 4 Batch 700 Loss 1.0525 Acc:0.6087\n",
            "Time taken for 1 epoch 77.9460 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.9892 Acc:0.6048\n",
            "Epoch 5 Batch 100 Loss 0.9075 Acc:0.6133\n",
            "Epoch 5 Batch 200 Loss 0.9202 Acc:0.5998\n",
            "Epoch 5 Batch 300 Loss 0.9030 Acc:0.6314\n",
            "Epoch 5 Batch 400 Loss 0.8959 Acc:0.6388\n",
            "Epoch 5 Batch 500 Loss 0.9343 Acc:0.6122\n",
            "Epoch 5 Batch 600 Loss 0.9668 Acc:0.6247\n",
            "Epoch 5 Batch 700 Loss 0.8409 Acc:0.6414\n",
            "Time taken for 1 epoch 76.4967 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.8216 Acc:0.6556\n",
            "Epoch 6 Batch 100 Loss 0.7914 Acc:0.6792\n",
            "Epoch 6 Batch 200 Loss 0.7687 Acc:0.6499\n",
            "Epoch 6 Batch 300 Loss 0.8231 Acc:0.6482\n",
            "Epoch 6 Batch 400 Loss 0.7994 Acc:0.6740\n",
            "Epoch 6 Batch 500 Loss 0.7782 Acc:0.6790\n",
            "Epoch 6 Batch 600 Loss 0.8057 Acc:0.6473\n",
            "Epoch 6 Batch 700 Loss 0.7777 Acc:0.6789\n",
            "Time taken for 1 epoch 77.2321 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.6421 Acc:0.7311\n",
            "Epoch 7 Batch 100 Loss 0.6204 Acc:0.7048\n",
            "Epoch 7 Batch 200 Loss 0.6300 Acc:0.7168\n",
            "Epoch 7 Batch 300 Loss 0.6546 Acc:0.7319\n",
            "Epoch 7 Batch 400 Loss 0.6317 Acc:0.7376\n",
            "Epoch 7 Batch 500 Loss 0.6914 Acc:0.7027\n",
            "Epoch 7 Batch 600 Loss 0.6497 Acc:0.7233\n",
            "Epoch 7 Batch 700 Loss 0.7417 Acc:0.6886\n",
            "Time taken for 1 epoch 76.3588 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.5436 Acc:0.7713\n",
            "Epoch 8 Batch 100 Loss 0.6046 Acc:0.7444\n",
            "Epoch 8 Batch 200 Loss 0.5728 Acc:0.7470\n",
            "Epoch 8 Batch 300 Loss 0.6095 Acc:0.7264\n",
            "Epoch 8 Batch 400 Loss 0.5572 Acc:0.7395\n",
            "Epoch 8 Batch 500 Loss 0.6182 Acc:0.7388\n",
            "Epoch 8 Batch 600 Loss 0.5651 Acc:0.7532\n",
            "Epoch 8 Batch 700 Loss 0.6506 Acc:0.7257\n",
            "Time taken for 1 epoch 77.2262 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.4749 Acc:0.7849\n",
            "Epoch 9 Batch 100 Loss 0.4399 Acc:0.7898\n",
            "Epoch 9 Batch 200 Loss 0.4759 Acc:0.7884\n",
            "Epoch 9 Batch 300 Loss 0.4974 Acc:0.7714\n",
            "Epoch 9 Batch 400 Loss 0.5212 Acc:0.7643\n",
            "Epoch 9 Batch 500 Loss 0.5130 Acc:0.7695\n",
            "Epoch 9 Batch 600 Loss 0.5328 Acc:0.7685\n",
            "Epoch 9 Batch 700 Loss 0.4859 Acc:0.7696\n",
            "Time taken for 1 epoch 76.5185 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.3784 Acc:0.8281\n",
            "Epoch 10 Batch 100 Loss 0.3948 Acc:0.8186\n",
            "Epoch 10 Batch 200 Loss 0.4145 Acc:0.8063\n",
            "Epoch 10 Batch 300 Loss 0.3972 Acc:0.8080\n",
            "Epoch 10 Batch 400 Loss 0.4335 Acc:0.7965\n",
            "Epoch 10 Batch 500 Loss 0.4400 Acc:0.7842\n",
            "Epoch 10 Batch 600 Loss 0.3887 Acc:0.8123\n",
            "Epoch 10 Batch 700 Loss 0.3561 Acc:0.8248\n",
            "Time taken for 1 epoch 76.9308 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.3301 Acc:0.8395\n",
            "Epoch 11 Batch 100 Loss 0.3232 Acc:0.8485\n",
            "Epoch 11 Batch 200 Loss 0.3223 Acc:0.8527\n",
            "Epoch 11 Batch 300 Loss 0.3323 Acc:0.8434\n",
            "Epoch 11 Batch 400 Loss 0.3552 Acc:0.8328\n",
            "Epoch 11 Batch 500 Loss 0.3407 Acc:0.8300\n",
            "Epoch 11 Batch 600 Loss 0.3693 Acc:0.8150\n",
            "Epoch 11 Batch 700 Loss 0.3711 Acc:0.8193\n",
            "Time taken for 1 epoch 75.8461 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.2687 Acc:0.8620\n",
            "Epoch 12 Batch 100 Loss 0.2686 Acc:0.8715\n",
            "Epoch 12 Batch 200 Loss 0.2756 Acc:0.8665\n",
            "Epoch 12 Batch 300 Loss 0.2760 Acc:0.8674\n",
            "Epoch 12 Batch 400 Loss 0.2871 Acc:0.8772\n",
            "Epoch 12 Batch 500 Loss 0.3221 Acc:0.8478\n",
            "Epoch 12 Batch 600 Loss 0.2942 Acc:0.8627\n",
            "Epoch 12 Batch 700 Loss 0.3085 Acc:0.8626\n",
            "Time taken for 1 epoch 76.7942 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.2144 Acc:0.8964\n",
            "Epoch 13 Batch 100 Loss 0.2262 Acc:0.8872\n",
            "Epoch 13 Batch 200 Loss 0.2462 Acc:0.8899\n",
            "Epoch 13 Batch 300 Loss 0.2108 Acc:0.9015\n",
            "Epoch 13 Batch 400 Loss 0.2690 Acc:0.8640\n",
            "Epoch 13 Batch 500 Loss 0.2603 Acc:0.8675\n",
            "Epoch 13 Batch 600 Loss 0.2602 Acc:0.8706\n",
            "Epoch 13 Batch 700 Loss 0.2489 Acc:0.8772\n",
            "Time taken for 1 epoch 76.2306 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.1690 Acc:0.9190\n",
            "Epoch 14 Batch 100 Loss 0.1828 Acc:0.9167\n",
            "Epoch 14 Batch 200 Loss 0.1803 Acc:0.9132\n",
            "Epoch 14 Batch 300 Loss 0.1801 Acc:0.9092\n",
            "Epoch 14 Batch 400 Loss 0.2116 Acc:0.8954\n",
            "Epoch 14 Batch 500 Loss 0.1916 Acc:0.9015\n",
            "Epoch 14 Batch 600 Loss 0.2219 Acc:0.8828\n",
            "Epoch 14 Batch 700 Loss 0.2168 Acc:0.8899\n",
            "Time taken for 1 epoch 76.7115 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.1575 Acc:0.9278\n",
            "Epoch 15 Batch 100 Loss 0.1480 Acc:0.9346\n",
            "Epoch 15 Batch 200 Loss 0.1567 Acc:0.9253\n",
            "Epoch 15 Batch 300 Loss 0.1562 Acc:0.9197\n",
            "Epoch 15 Batch 400 Loss 0.1497 Acc:0.9263\n",
            "Epoch 15 Batch 500 Loss 0.1794 Acc:0.9084\n",
            "Epoch 15 Batch 600 Loss 0.1661 Acc:0.9229\n",
            "Epoch 15 Batch 700 Loss 0.2218 Acc:0.8696\n",
            "Time taken for 1 epoch 75.9673 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.1239 Acc:0.9346\n",
            "Epoch 16 Batch 100 Loss 0.1273 Acc:0.9454\n",
            "Epoch 16 Batch 200 Loss 0.1487 Acc:0.9269\n",
            "Epoch 16 Batch 300 Loss 0.1331 Acc:0.9382\n",
            "Epoch 16 Batch 400 Loss 0.1433 Acc:0.9269\n",
            "Epoch 16 Batch 500 Loss 0.1644 Acc:0.9197\n",
            "Epoch 16 Batch 600 Loss 0.1695 Acc:0.9096\n",
            "Epoch 16 Batch 700 Loss 0.1605 Acc:0.9198\n",
            "Time taken for 1 epoch 76.9687 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.1055 Acc:0.9562\n",
            "Epoch 17 Batch 100 Loss 0.1071 Acc:0.9488\n",
            "Epoch 17 Batch 200 Loss 0.1083 Acc:0.9341\n",
            "Epoch 17 Batch 300 Loss 0.1304 Acc:0.9361\n",
            "Epoch 17 Batch 400 Loss 0.1309 Acc:0.9375\n",
            "Epoch 17 Batch 500 Loss 0.1229 Acc:0.9417\n",
            "Epoch 17 Batch 600 Loss 0.1320 Acc:0.9342\n",
            "Epoch 17 Batch 700 Loss 0.1500 Acc:0.9274\n",
            "Time taken for 1 epoch 76.2917 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.0871 Acc:0.9589\n",
            "Epoch 18 Batch 100 Loss 0.0865 Acc:0.9606\n",
            "Epoch 18 Batch 200 Loss 0.1148 Acc:0.9466\n",
            "Epoch 18 Batch 300 Loss 0.1264 Acc:0.9432\n",
            "Epoch 18 Batch 400 Loss 0.1154 Acc:0.9490\n",
            "Epoch 18 Batch 500 Loss 0.1004 Acc:0.9498\n",
            "Epoch 18 Batch 600 Loss 0.1156 Acc:0.9430\n",
            "Epoch 18 Batch 700 Loss 0.1361 Acc:0.9340\n",
            "Time taken for 1 epoch 77.1923 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.0931 Acc:0.9556\n",
            "Epoch 19 Batch 100 Loss 0.0980 Acc:0.9502\n",
            "Epoch 19 Batch 200 Loss 0.0823 Acc:0.9663\n",
            "Epoch 19 Batch 300 Loss 0.0740 Acc:0.9608\n",
            "Epoch 19 Batch 400 Loss 0.0961 Acc:0.9435\n",
            "Epoch 19 Batch 500 Loss 0.1239 Acc:0.9469\n",
            "Epoch 19 Batch 600 Loss 0.0910 Acc:0.9534\n",
            "Epoch 19 Batch 700 Loss 0.0990 Acc:0.9501\n",
            "Time taken for 1 epoch 75.9130 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.0777 Acc:0.9596\n",
            "Epoch 20 Batch 100 Loss 0.0644 Acc:0.9683\n",
            "Epoch 20 Batch 200 Loss 0.0757 Acc:0.9625\n",
            "Epoch 20 Batch 300 Loss 0.0853 Acc:0.9579\n",
            "Epoch 20 Batch 400 Loss 0.0697 Acc:0.9661\n",
            "Epoch 20 Batch 500 Loss 0.0852 Acc:0.9526\n",
            "Epoch 20 Batch 600 Loss 0.0893 Acc:0.9595\n",
            "Epoch 20 Batch 700 Loss 0.1020 Acc:0.9455\n",
            "Time taken for 1 epoch 77.6050 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "ATeh7SnuC-OY",
        "outputId": "d4a73fa4-11a2-433d-b849-c95bbc7b1cea"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
        "# plot some data\n",
        "ax1.plot(losses, label='loss')\n",
        "#plt.plot(results.history['val_loss'], label='val_loss')\n",
        "ax1.set_title('Training Loss')\n",
        "ax1.legend()\n",
        "# accuracies\n",
        "ax2.plot(accuracies, label='acc')\n",
        "#plt.plot(results.history['val_accuracy_fn'], label='val_acc')\n",
        "ax2.set_title('Training Accuracy')\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKDN5aJJDBa8",
        "outputId": "9a2aa414-ee3e-443a-9296-717324eeb538"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint_dir = '/content/drive/MyDrive/machine-translation/models/spa-eng/training_ckpt_seq2seq'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f05c1d07b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT8GxJv1DNzw"
      },
      "source": [
        "def predict(input_text, encoder, input_max_len, tokenizer_inputs, word2idx_outputs, idx2word_outputs):\n",
        "    if input_text is None:\n",
        "        input_text = input_data[np.random.choice(len(input_data))]\n",
        "        print(input_text)\n",
        "    # Tokenize the input sequence\n",
        "    input_seq = tokenizer_inputs.texts_to_sequences([input_text])\n",
        "    # Pad the sentence\n",
        "    input_seq = pad_sequences(input_seq, maxlen=input_max_len, padding='post')\n",
        "    print(input_seq)\n",
        "    # Set the encoder initial state\n",
        "    en_initial_states = encoder.init_states(1)\n",
        "    en_outputs = encoder(tf.constant(input_seq), en_initial_states)\n",
        "    # Create the decoder input, the sos token\n",
        "    de_input = tf.constant([[word2idx_outputs['<sos>']]])\n",
        "    # Set the decoder states to the encoder vector or encoder hidden state\n",
        "    de_state_h, de_state_c = en_outputs[1:]\n",
        "    \n",
        "    out_words = []\n",
        "    while True:\n",
        "        # Decode and get the output probabilities\n",
        "        de_output, de_state_h, de_state_c = decoder(\n",
        "            de_input, (de_state_h, de_state_c))\n",
        "        # Select the word with the highest probability\n",
        "        de_input = tf.argmax(de_output, -1)\n",
        "        # Append the word to the predicted output\n",
        "        out_words.append(idx2word_outputs[de_input.numpy()[0][0]])\n",
        "        # Finish when eos token is found or the max length is reached\n",
        "        if out_words[-1] == '<eos>' or len(out_words) >= 20:\n",
        "            break\n",
        "\n",
        "    print(' '.join(out_words))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trS8IIEvDS9M",
        "outputId": "08febcdc-63b6-45a8-e4d0-027e1be5aa0f"
      },
      "source": [
        "test_sents = [input_data[5000], input_data[10000], input_data[15000], input_data[20000],\n",
        "input_data[25000], input_data[30000], input_data[35000], input_data[40000], input_data[45000], input_data[50000], \n",
        "input_data[55000], input_data[60000], input_data[65000], input_data[70000], input_data[75000], input_data[80000],\n",
        "input_data[85000], input_data[90000], input_data[95000]]\n",
        "#test_sents = [encoder_inputs[1000]]\n",
        "print(test_sents)\n",
        "for test_sent in test_sents:\n",
        "    predict(test_sent, encoder, input_max_len, tokenizer_inputs, word2idx_outputs, idx2word_outputs)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tengo que intentarlo .', 'eso es increible !', '¿ teneis un carro ?', '¿ esta es la mujer de tom ?', 'dile a tom que se presente .', 'tom perdio las gafas .', '¿ que puedo hacer por ustedes ?', '¿ donde estudias ?', 'deberias ir personalmente .', 'un cocodrilo se comio a tom .', '¿ tienes alguna experiencia ?', 'el estuvo muy malhumorado anoche .', '¿ cuanto dinero tiene tom ?', 'solo quiero volverme a la cama .', 'soy el benjamin de la familia .', 'ahora lleva puesto un precioso vestido .', 'ayer , tom no tenia nada para comer .', 'todo el mundo quiere vivir confortablemente .', 'los soldados deben obedecer a sus comandantes .']\n",
            "[[  40    2 1292    1    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]]\n",
            "i have to try . <eos>\n",
            "[[  31   11 1932   53    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]]\n",
            "it s incredible ! <eos>\n",
            "[[  6 800  12 713   5   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]]\n",
            "do you have a car ? <eos>\n",
            "[[  6  16  11  10 278   9   3   5   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]]\n",
            "is this tom s wife ? <eos>\n",
            "[[ 872    8    3    2   15 1752    1    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]]\n",
            "tell tom to pick up . <eos>\n",
            "[[   3  458   30 1086    1    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]]\n",
            "tom lost his glasses . <eos>\n",
            "[[  6   2  45  52  17 200   5   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]]\n",
            "what can i do for you ? <eos>\n",
            "[[   6   57 2081    5    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]]\n",
            "where are you studying ? <eos>\n",
            "[[ 180   67 2583    1    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]]\n",
            "you should go to sleep . <eos>\n",
            "[[  12 6759   15  607    8    3    1    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]]\n",
            "a crocodile has eaten tom . <eos>\n",
            "[[   6   83  195 1109    5    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]]\n",
            "do you have any experience ? <eos>\n",
            "[[   7  306   38 8269  319    1    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]]\n",
            "he was so cranky last night . <eos>\n",
            "[[  6 151  97  39   3   5   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]]\n",
            "how much money does tom have ? <eos>\n",
            "[[  62   42 5829    8   10  243    1    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]]\n",
            "i just want to go back to bed . <eos>\n",
            "[[   69     7 17233     9    10   295     1     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]]\n",
            "i m the youngest in the family . <eos>\n",
            "[[  77  427  685   12 4116  620    1    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]]\n",
            "she is wearing a nice dress now . <eos>\n",
            "[[138  22   3   4 132  66  34 141   1   0   0   0   0   0   0   0   0   0\n",
            "    0   0]]\n",
            "tom had nothing to eat yesterday . <eos>\n",
            "[[   54     7   207    98   337 18807     1     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]]\n",
            "everybody wants to live in comfort . <eos>\n",
            "[[   26  1788  1450  2325     8   120 19366     1     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]]\n",
            "soldiers must obey their commanders . <eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgpFiTqHI-Qw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}